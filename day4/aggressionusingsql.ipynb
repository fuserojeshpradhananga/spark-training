{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Aggregations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Initialize PySpark Session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, when, lit , avg, coalesce , struct,array , explode, create_map,approx_count_distinct,sumDistinct, sum, mean\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"day4\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Chipotle dataset into a Spark DataFrame\n",
    "data_path = \"./US_Crime_Rates_1960_2014.csv\"  # Replace with the actual path\n",
    "US_df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "\n",
    "# Load the Chipotle dataset into a Spark DataFrame\n",
    "data_path = \"./titanic.csv\"  # Replace with the actual path\n",
    "titanic_df = spark.read.csv(data_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a temporary view for the \"US_df\" DataFrame\n",
    "US_df.createOrReplaceTempView(\"us_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Population: integer (nullable = true)\n",
      " |-- Total: integer (nullable = true)\n",
      " |-- Violent: integer (nullable = true)\n",
      " |-- Property: integer (nullable = true)\n",
      " |-- Murder: integer (nullable = true)\n",
      " |-- Forcible_Rape: integer (nullable = true)\n",
      " |-- Robbery: integer (nullable = true)\n",
      " |-- Aggravated_assault: integer (nullable = true)\n",
      " |-- Burglary: integer (nullable = true)\n",
      " |-- Larceny_Theft: integer (nullable = true)\n",
      " |-- Vehicle_Theft: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "US_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count\n",
    "\n",
    "Question: How many records are there in the US_Crime_Rates_1960_2014_df DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 55\n"
     ]
    }
   ],
   "source": [
    "#counting the number of records in the \"US_df\" DataFrame\n",
    "record_count = spark.sql(\"SELECT COUNT(*) AS record_count FROM us_data\")\n",
    "result = record_count.first()\n",
    "\n",
    "# Extract the count from the result\n",
    "count = result['record_count']\n",
    "print(\"Number of records:\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### countDistinct\n",
    "Question: How many distinct years are present in the US_Crime_Rates_1960_2014_df DataFrame?\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct years: 55\n"
     ]
    }
   ],
   "source": [
    "#counting the number of distinct years in the dataframe\n",
    "distinct_years_count = spark.sql(\"SELECT COUNT(DISTINCT Year) AS distinct_years_count FROM us_data\")\n",
    "result = distinct_years_count.first()\n",
    "\n",
    "#extracting the count from the result\n",
    "count = result['distinct_years_count']\n",
    "print(\"Number of distinct years:\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### approx_count_distinct\n",
    "\n",
    "Question: Estimate the approximate number of distinct values in the \"Total\" column of the US_Crime_Rates_1960_2014_df DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate distinct values in 'Total' column: 55\n"
     ]
    }
   ],
   "source": [
    "#estimating the approximate number of distinct values in the \"Total\" column\n",
    "approx_distinct_count = spark.sql(\"SELECT approx_count_distinct(Total) AS approx_distinct_total FROM us_data\")\n",
    "result = approx_distinct_count.first()\n",
    "\n",
    "#extracting\n",
    "#  the estimated count from the result\n",
    "approx_count = result['approx_distinct_total']\n",
    "print(\"Approximate distinct values in 'Total' column:\", approx_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  first and last\n",
    "\n",
    "Question: Find the first and last year in the US_Crime_Rates_1960_2014_df DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First year: 1960\n",
      "Last year: 2014\n"
     ]
    }
   ],
   "source": [
    "#finding the first and last year in the dataframe\n",
    "year_stats = spark.sql(\"\"\"\n",
    "    SELECT MIN(Year) AS first_year, MAX(Year) AS last_year\n",
    "    FROM us_data\n",
    "\"\"\")\n",
    "result = year_stats.first()\n",
    "\n",
    "#extracting the first and last year from the result\n",
    "first_year = result['first_year']\n",
    "last_year = result['last_year']\n",
    "\n",
    "print(\"First year:\", first_year)\n",
    "print(\"Last year:\", last_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### min and max\n",
    "\n",
    "Question: Find the minimum and maximum population values in the US_Crime_Rates_1960_2014_df DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum population: 179323175\n",
      "Maximum population: 318857056\n"
     ]
    }
   ],
   "source": [
    "#finding the minimum and maximum population values in the dataframe\n",
    "population_stats = spark.sql(\"\"\"\n",
    "    SELECT MIN(Population) AS min_population, MAX(Population) AS max_population\n",
    "    FROM us_data\n",
    "\"\"\")\n",
    "result = population_stats.first()\n",
    "\n",
    "#extracting the minimum and maximum population values from the result\n",
    "min_population = result['min_population']\n",
    "max_population = result['max_population']\n",
    "\n",
    "print(\"Minimum population:\", min_population)\n",
    "print(\"Maximum population:\", max_population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sumDistinct\n",
    "\n",
    "Question: Calculate the sum of distinct \"Property\" values for each year in the US_Crime_Rates_1960_2014_df DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+\n",
      "|Year|Sumdistinctproperty|\n",
      "+----+-------------------+\n",
      "|1960|            3095700|\n",
      "|1961|            3198600|\n",
      "|1962|            3450700|\n",
      "|1963|            3792500|\n",
      "|1964|            4200400|\n",
      "|1965|            4352000|\n",
      "|1966|            4793300|\n",
      "|1967|            5403500|\n",
      "|1968|            6125200|\n",
      "|1969|            6749000|\n",
      "|1970|            7359200|\n",
      "|1971|            7771700|\n",
      "|1972|            7413900|\n",
      "|1973|            7842200|\n",
      "|1974|            9278700|\n",
      "|1975|           10252700|\n",
      "|1976|           10345500|\n",
      "|1977|            9955000|\n",
      "|1978|           10123400|\n",
      "|1979|           11041500|\n",
      "+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculating the sum of distinct \"Property\" values for each year\n",
    "\n",
    "distinct_property_sum = spark.sql(\"\"\"\n",
    "    SELECT Year, SUM(DISTINCT Property) AS Sumdistinctproperty\n",
    "    FROM us_data\n",
    "    GROUP BY Year\n",
    "    ORDER BY Year\n",
    "\"\"\")\n",
    "#showing the values\n",
    "distinct_property_sum.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### avg\n",
    "\n",
    "Question: Calculate the average \"Murder\" rate for the entire dataset in the US_Crime_Rates_1960_2014_df DataFrame.\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Murder rate: 17317.236363636363\n"
     ]
    }
   ],
   "source": [
    "#calculating the average \"Murder\" rate for the entire dataset\n",
    "average_murder_rate = spark.sql(\"SELECT AVG(Murder) AS avg_murder_rate FROM us_data\")\n",
    "result = average_murder_rate.first()\n",
    "\n",
    "#extracting the average \"Murder\" rate from the result\n",
    "avg_murder_rate = result['avg_murder_rate']\n",
    "\n",
    "print(\"Average Murder rate:\", avg_murder_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating to Complex Types\n",
    "\n",
    "Question: Calculate the total sum of \"Violent\" and \"Property\" crimes for each year in the US_Crime_Rates_1960_2014_df DataFrame. Store the results in a struct type column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+\n",
      "|Year|CrimeTotals        |\n",
      "+----+-------------------+\n",
      "|1960|{288460, 3095700}  |\n",
      "|1961|{289390, 3198600}  |\n",
      "|1962|{301510, 3450700}  |\n",
      "|1963|{316970, 3792500}  |\n",
      "|1964|{364220, 4200400}  |\n",
      "|1965|{387390, 4352000}  |\n",
      "|1966|{430180, 4793300}  |\n",
      "|1967|{499930, 5403500}  |\n",
      "|1968|{595010, 6125200}  |\n",
      "|1969|{661870, 6749000}  |\n",
      "|1970|{738820, 7359200}  |\n",
      "|1971|{816500, 7771700}  |\n",
      "|1972|{834900, 7413900}  |\n",
      "|1973|{875910, 7842200}  |\n",
      "|1974|{974720, 9278700}  |\n",
      "|1975|{1039710, 10252700}|\n",
      "|1976|{1004210, 10345500}|\n",
      "|1977|{1029580, 9955000} |\n",
      "|1978|{1085550, 10123400}|\n",
      "|1979|{1208030, 11041500}|\n",
      "+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculating the total sum of \"Violent\" and \"Property\" crimes for each year and create a struct column\n",
    "result_with_struct = spark.sql(\"\"\"\n",
    "    SELECT Year, \n",
    "           struct(SUM(Violent) AS TotalViolent, SUM(Property) AS TotalProperty) AS CrimeTotals\n",
    "    FROM us_data\n",
    "    GROUP BY Year\n",
    "    ORDER BY Year\n",
    "\"\"\")\n",
    "result_with_struct.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping\n",
    "\n",
    "Question: In the given US_Crime_Rates_1960_2014_df DataFrame, you are tasked with finding the average of all crimes combined for each year. Calculate the sum of all crime categories (Violent, Property, Murder, Forcible_Rape, Robbery, Aggravated_assault, Burglary, Larceny_Theft, Vehicle_Theft) for each year and then determine the average of these combined crime sums. Provide the result as the average of all crimes across the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "| AvgAllCrimes|\n",
      "+-------------+\n",
      "|1.166085038E9|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the sum of all crime categories for each year\n",
    "crime_sums = spark.sql(\"\"\"\n",
    "    SELECT Year, \n",
    "           SUM(Violent + Property + Murder + Forcible_Rape + Robbery + Aggravated_assault + Burglary + Larceny_Theft + Vehicle_Theft) AS TotalCrime\n",
    "    FROM us_data\n",
    "    GROUP BY Year\n",
    "    ORDER BY Year\n",
    "\"\"\")\n",
    "\n",
    "# Calculate the average of all crimes across the entire dataset\n",
    "average_all_crimes = spark.sql(\"\"\"\n",
    "    SELECT AVG(TotalCrime) AS AvgAllCrimes\n",
    "    FROM (\n",
    "        SELECT SUM(Violent + Property + Murder + Forcible_Rape + Robbery + Aggravated_assault + Burglary + Larceny_Theft + Vehicle_Theft) AS TotalCrime\n",
    "        FROM us_data\n",
    "    )\n",
    "\"\"\")\n",
    "                               \n",
    "average_all_crimes.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping\n",
    "\n",
    "Question: In the given US_Crime_Rates_1960_2014_df DataFrame, you are tasked with finding the average of all crimes combined for each year. Calculate the sum of all crime categories (Violent, Property, Murder, Forcible_Rape, Robbery, Aggravated_assault, Burglary, Larceny_Theft, Vehicle_Theft) for each year and then determine the average of these combined crime sums. Provide the result as the average of all crimes across the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of all crime: 21201546.145454545\n",
      "+----+---------------+\n",
      "|year|total_crime_sum|\n",
      "+----+---------------+\n",
      "|1960|        6768320|\n",
      "|1961|        6975980|\n",
      "|1962|        7504420|\n",
      "|1963|        8218940|\n",
      "|1964|        9129240|\n",
      "|1965|        9478780|\n",
      "|1966|       10446960|\n",
      "|1967|       11806860|\n",
      "|1968|       13440420|\n",
      "|1969|       14821740|\n",
      "|1970|       16196040|\n",
      "|1971|       17176400|\n",
      "|1972|       16497600|\n",
      "|1973|       17436220|\n",
      "|1974|       20506940|\n",
      "|1975|       22584730|\n",
      "|1976|       22699410|\n",
      "|1977|       21969060|\n",
      "|1978|       22417910|\n",
      "|1979|       24499060|\n",
      "+----+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculating the total sum of all crime categories for each year\n",
    "total_sum = spark.sql(\"\"\" \n",
    "                      SELECT *,\n",
    "                            (Violent + Property + Murder + Forcible_rape + Robbery +\n",
    "                            Aggravated_assault + Burglary + Larceny_Theft + Vehicle_Theft) AS Total_crime_sum\n",
    "                     FROM us_data\n",
    "                    \"\"\")\n",
    "\n",
    "# total_sum.show()\n",
    "\n",
    "\n",
    "avegare_crime = total_sum.agg(avg('total_crime_sum'))\n",
    "print(f\"Average of all crime: {avegare_crime.collect()[0][0]}\")\n",
    "\n",
    "total_sum.select('year','total_crime_sum').show()\n",
    "# avegare_crime.show()\n",
    "# average_crime = total_sum.groupBy('year').agg(avg('total_crime_sum').alias('average_crime'))\n",
    "# average_crime.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window Functions\n",
    "\n",
    "Question: Calculate the cumulative sum of \"Property\" values over the years using a window function in the US_Crime_Rates_1960_2014_df DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+--------+-------+--------+------+-------------+-------+------------------+--------+-------------+-------------+-----------------------+\n",
      "|Year|Population|   Total|Violent|Property|Murder|Forcible_Rape|Robbery|Aggravated_assault|Burglary|Larceny_Theft|Vehicle_Theft|Cumulative_Property_Sum|\n",
      "+----+----------+--------+-------+--------+------+-------------+-------+------------------+--------+-------------+-------------+-----------------------+\n",
      "|1960| 179323175| 3384200| 288460| 3095700|  9110|        17190| 107840|            154320|  912100|      1855400|       328200|                3095700|\n",
      "|1961| 182992000| 3488000| 289390| 3198600|  8740|        17220| 106670|            156760|  949600|      1913000|       336000|                3198600|\n",
      "|1962| 185771000| 3752200| 301510| 3450700|  8530|        17550| 110860|            164570|  994300|      2089600|       366800|                3450700|\n",
      "|1963| 188483000| 4109500| 316970| 3792500|  8640|        17650| 116470|            174210| 1086400|      2297800|       408300|                3792500|\n",
      "|1964| 191141000| 4564600| 364220| 4200400|  9360|        21420| 130390|            203050| 1213200|      2514400|       472800|                4200400|\n",
      "|1965| 193526000| 4739400| 387390| 4352000|  9960|        23410| 138690|            215330| 1282500|      2572600|       496900|                4352000|\n",
      "|1966| 195576000| 5223500| 430180| 4793300| 11040|        25820| 157990|            235330| 1410100|      2822000|       561200|                4793300|\n",
      "|1967| 197457000| 5903400| 499930| 5403500| 12240|        27620| 202910|            257160| 1632100|      3111600|       659800|                5403500|\n",
      "|1968| 199399000| 6720200| 595010| 6125200| 13800|        31670| 262840|            286700| 1858900|      3482700|       783600|                6125200|\n",
      "|1969| 201385000| 7410900| 661870| 6749000| 14760|        37170| 298850|            311090| 1981900|      3888600|       878500|                6749000|\n",
      "|1970| 203235298| 8098000| 738820| 7359200| 16000|        37990| 349860|            334970| 2205000|      4225800|       928400|                7359200|\n",
      "|1971| 206212000| 8588200| 816500| 7771700| 17780|        42260| 387700|            368760| 2399300|      4424200|       948200|                7771700|\n",
      "|1972| 208230000| 8248800| 834900| 7413900| 18670|        46850| 376290|            393090| 2375500|      4151200|       887200|                7413900|\n",
      "|1973| 209851000| 8718100| 875910| 7842200| 19640|        51400| 384220|            420650| 2565500|      4347900|       928800|                7842200|\n",
      "|1974| 211392000|10253400| 974720| 9278700| 20710|        55400| 442400|            456210| 3039200|      5262500|       977100|                9278700|\n",
      "|1975| 213124000|11292400|1039710|10252700| 20510|        56090| 470500|            492620| 3265300|      5977700|      1009600|               10252700|\n",
      "|1976| 214659000|11349700|1004210|10345500| 18780|        57080| 427810|            500530| 3108700|      6270800|       966000|               10345500|\n",
      "|1977| 216332000|10984500|1029580| 9955000| 19120|        63500| 412610|            534350| 3071500|      5905700|       977700|                9955000|\n",
      "|1978| 218059000|11209000|1085550|10123400| 19560|        67610| 426930|            571460| 3128300|      5991000|      1004100|               10123400|\n",
      "|1979| 220099000|12249500|1208030|11041500| 21460|        76390| 480700|            629480| 3327700|      6601000|      1112800|               11041500|\n",
      "+----+----------+--------+-------+--------+------+-------------+-------+------------------+--------+-------------+-------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the cumulative sum of \"Property\" values with a partition specification\n",
    "cumulative_property_sum = spark.sql(\"\"\"\n",
    "    SELECT *,\n",
    "           SUM(Property) OVER (PARTITION BY Year ORDER BY Year) AS Cumulative_Property_Sum\n",
    "    FROM us_data\n",
    "    ORDER BY Year\n",
    "\"\"\")\n",
    "\n",
    "# Show the result\n",
    "cumulative_property_sum.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot\n",
    "Question: You are working with a DataFrame named US_Crime_Rates_1960_2014_df that contains crime data for different crime types over the years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
