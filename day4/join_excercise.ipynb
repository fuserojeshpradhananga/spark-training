{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/03 09:34:29 WARN Utils: Your hostname, rojesh-Predator-PHN16-71 resolves to a loopback address: 127.0.1.1; using 192.168.254.218 instead (on interface wlp0s20f3)\n",
      "23/09/03 09:34:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/03 09:34:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, when, lit , avg, coalesce , struct,array , explode, create_map\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"day4\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+\n",
      "|employee_id|employee_name|department_id|\n",
      "+-----------+-------------+-------------+\n",
      "|          1|  Pallavi mam|          101|\n",
      "|          2|          Bob|          102|\n",
      "|          3|        Cathy|          101|\n",
      "|          4|        David|          103|\n",
      "|          5|    Amrit Sir|          104|\n",
      "|          6|        Alice|         null|\n",
      "|          7|          Eva|         null|\n",
      "|          8|        Frank|          110|\n",
      "|          9|        Grace|          109|\n",
      "|         10|        Henry|         null|\n",
      "+-----------+-------------+-------------+\n",
      "\n",
      "+-------------+--------------------+\n",
      "|department_id|     department_name|\n",
      "+-------------+--------------------+\n",
      "|          101|                  HR|\n",
      "|          102|         Engineering|\n",
      "|          103|             Finance|\n",
      "|          104|           Marketing|\n",
      "|          105|          Operations|\n",
      "|          106|                null|\n",
      "|          107|          Operations|\n",
      "|          108|          Production|\n",
      "|         null|             Finance|\n",
      "|          110|Research and Deve...|\n",
      "+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#defining the schema for employees_df\n",
    "employees_schema = StructType([\n",
    "    StructField(\"employee_id\", IntegerType(), True),\n",
    "    StructField(\"employee_name\", StringType(), True),\n",
    "    StructField(\"department_id\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "#creating employees_df DataFrame\n",
    "employees_data = [\n",
    "    (1, \"Pallavi mam\", 101),\n",
    "    (2, \"Bob\", 102),\n",
    "    (3, \"Cathy\", 101),\n",
    "    (4, \"David\", 103),\n",
    "    (5, \"Amrit Sir\", 104),\n",
    "    (6, \"Alice\", None),\n",
    "    (7, \"Eva\", None),\n",
    "    (8, \"Frank\", 110),\n",
    "    (9, \"Grace\", 109),\n",
    "    (10, \"Henry\", None)\n",
    "]\n",
    "\n",
    "employees_df = spark.createDataFrame(employees_data, schema=employees_schema)\n",
    "\n",
    "#defining the schema for departments_df\n",
    "departments_schema = StructType([\n",
    "    StructField(\"department_id\", IntegerType(), True),\n",
    "    StructField(\"department_name\", StringType(), True)\n",
    "])\n",
    "\n",
    "#creating departments_df DataFrame\n",
    "departments_data = [\n",
    "    (101, \"HR\"),\n",
    "    (102, \"Engineering\"),\n",
    "    (103, \"Finance\"),\n",
    "    (104, \"Marketing\"),\n",
    "    (105, \"Operations\"),\n",
    "    (106, None),\n",
    "    (107, \"Operations\"),\n",
    "    (108, \"Production\"),\n",
    "    (None, \"Finance\"),\n",
    "    (110, \"Research and Development\")\n",
    "]\n",
    "\n",
    "departments_df = spark.createDataFrame(departments_data, schema=departments_schema)\n",
    "\n",
    "#showing the DataFrames\n",
    "employees_df.show()\n",
    "departments_df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_id: integer (nullable = true)\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department_id: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- department_id: integer (nullable = true)\n",
      " |-- department_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.printSchema()\n",
    "\n",
    "\n",
    "departments_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Expressions\n",
    "\n",
    "Question: How can you combine the employees_df and departments_df DataFrames based on the common \"department_id\" column to get a combined DataFrame with employee names and their respective department names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+\n",
      "|employee_name|     department_name|\n",
      "+-------------+--------------------+\n",
      "|  Pallavi mam|                  HR|\n",
      "|        Cathy|                  HR|\n",
      "|          Bob|         Engineering|\n",
      "|        David|             Finance|\n",
      "|    Amrit Sir|           Marketing|\n",
      "|        Frank|Research and Deve...|\n",
      "+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#combining the DataFrames using an inner join on the \"department_id\" column\n",
    "combined_df = employees_df.join(departments_df, on='department_id', how='inner')\n",
    "\n",
    "#selecting the columns you want to keep in the combined DataFrame\n",
    "selected_columns = [\"employee_name\", \"department_name\"]\n",
    "\n",
    "#selecting only the desired columns\n",
    "result_df = combined_df.select(selected_columns)\n",
    "\n",
    "#showing the result DataFrame\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inner Joins\n",
    "\n",
    "Question: How can you retrieve employee names and their respective department names for employees belonging to the \"Engineering\" department?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+\n",
      "|employee_name|department_name|\n",
      "+-------------+---------------+\n",
      "|          Bob|    Engineering|\n",
      "+-------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#combining the DataFrames using an inner join on the \"department_id\" column\n",
    "combined_df = employees_df.join(departments_df, on='department_id', how='inner')\n",
    "\n",
    "#filtering the combined DataFrame to get employees in the \"Engineering\" department\n",
    "engineering_employees_df = combined_df.filter(combined_df.department_name == \"Engineering\")\n",
    "\n",
    "#selecting employee names and department names\n",
    "result_df = engineering_employees_df.select(\"employee_name\", \"department_name\")\n",
    "\n",
    "#showing the result DataFrame\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+\n",
      "|     department_name|employee_name|\n",
      "+--------------------+-------------+\n",
      "|                  HR|  Pallavi mam|\n",
      "|         Engineering|          Bob|\n",
      "|                  HR|        Cathy|\n",
      "|             Finance|        David|\n",
      "|           Marketing|    Amrit Sir|\n",
      "|                null|        Alice|\n",
      "|                null|          Eva|\n",
      "|Research and Deve...|        Frank|\n",
      "|                null|        Grace|\n",
      "|                null|        Henry|\n",
      "+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#renaming the \"department_id\" column in employees_df to match departments_df\n",
    "employees_df = employees_df.withColumnRenamed(\"department_id\", \"dept_id\")\n",
    "\n",
    "#performing a right outer join on the renamed \"dept_id\" column\n",
    "all_departments_df = departments_df.join(employees_df, departments_df[\"department_id\"] == employees_df[\"dept_id\"], \"right_outer\")\n",
    "\n",
    "#replacing null employee names with \"No Employees\"\n",
    "result_df = all_departments_df.withColumn(\n",
    "    \"employee_name\",\n",
    "    coalesce(all_departments_df[\"employee_name\"], lit(\"No Employees\"))\n",
    ")\n",
    "\n",
    "#selecting department names and employee names\n",
    "result_df = result_df.select(\"department_name\", \"employee_name\")\n",
    "\n",
    "#showing the result DataFrame\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left Outer Joins\n",
    "\n",
    "Question: List all employees along with their department names. If an employee doesn't have a department assigned, display \"No Department\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+\n",
      "|employee_name|     department_name|\n",
      "+-------------+--------------------+\n",
      "|  Pallavi mam|                  HR|\n",
      "|          Bob|         Engineering|\n",
      "|        Cathy|                  HR|\n",
      "|        David|             Finance|\n",
      "|    Amrit Sir|           Marketing|\n",
      "|        Alice|       No Department|\n",
      "|          Eva|       No Department|\n",
      "|        Frank|Research and Deve...|\n",
      "|        Grace|       No Department|\n",
      "|        Henry|       No Department|\n",
      "+-------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#performing a left outer join on the renamed \"dept_id\" column\n",
    "all_employees_df = employees_df.join(departments_df, employees_df[\"dept_id\"] == departments_df[\"department_id\"], \"left_outer\")\n",
    "\n",
    "#replacing null department names with \"No Department\"\n",
    "result_df = all_employees_df.withColumn(\n",
    "    \"department_name\",\n",
    "    coalesce(all_employees_df[\"department_name\"], lit(\"No Department\"))\n",
    ")\n",
    "\n",
    "#selecting employee names and department names\n",
    "result_df2 = result_df.select(\"employee_name\", \"department_name\")\n",
    "\n",
    "#shwoing the result DataFrame\n",
    "result_df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right Outer Joins\n",
    "\n",
    "Question: Display a list of departments along with employee names. If a department has no employees, display \"No Employees\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+\n",
      "|     department_name|employee_name|\n",
      "+--------------------+-------------+\n",
      "|                  HR|  Pallavi mam|\n",
      "|         Engineering|          Bob|\n",
      "|                  HR|        Cathy|\n",
      "|             Finance|        David|\n",
      "|           Marketing|    Amrit Sir|\n",
      "|        No Employees|        Alice|\n",
      "|        No Employees|          Eva|\n",
      "|Research and Deve...|        Frank|\n",
      "|        No Employees|        Grace|\n",
      "|        No Employees|        Henry|\n",
      "+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#renaming the \"department_id\" column in employees_df to match departments_df\n",
    "employees_df = employees_df.withColumnRenamed(\"department_id\", \"dept_id\")\n",
    "\n",
    "#performing a right outer join on the renamed \"dept_id\" column\n",
    "all_departments_df = departments_df.join(employees_df, departments_df[\"department_id\"] == employees_df[\"dept_id\"], \"right_outer\")\n",
    "\n",
    "#replacing null department names with \"No Employees\" and null employee names with \"No Employee\"\n",
    "result_df = all_departments_df.withColumn(\n",
    "    \"department_name\",\n",
    "    coalesce(all_departments_df[\"department_name\"], lit(\"No Employees\"))\n",
    ").withColumn(\n",
    "    \"employee_name\",\n",
    "    coalesce(all_departments_df[\"employee_name\"], lit(\"No Employee\"))\n",
    ")\n",
    "\n",
    "#selecting department names and employee names\n",
    "result_df = result_df.select(\"department_name\", \"employee_name\")\n",
    "\n",
    "#shweing the result DataFrame\n",
    "\n",
    "result_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left Semi Joins\n",
    "\n",
    "Question: Retrieve a DataFrame that includes employee names for departments that have employees.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `employee_name` cannot be resolved. Did you mean one of the following? [`department_name`, `dept_id`].;\n'Project [department_name#39, 'employee_name]\n+- Join LeftSemi, (dept_id#188 = dept_id#94)\n   :- Project [department_id#38 AS dept_id#188, department_name#39]\n   :  +- LogicalRDD [department_id#38, department_name#39], false\n   +- Project [employee_id#32, employee_name#33, department_id#34 AS dept_id#94]\n      +- LogicalRDD [employee_id#32, employee_name#33, department_id#34], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 13\u001b[0m\n\u001b[1;32m      6\u001b[0m departments_with_employees_df \u001b[39m=\u001b[39m departments_df\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m      7\u001b[0m     employees_df,\n\u001b[1;32m      8\u001b[0m     departments_df[\u001b[39m\"\u001b[39m\u001b[39mdept_id\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m employees_df[\u001b[39m\"\u001b[39m\u001b[39mdept_id\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m      9\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mleft_semi\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[39m#selecting department names and employee names\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m result_df \u001b[39m=\u001b[39m departments_with_employees_df\u001b[39m.\u001b[39;49mselect(col(\u001b[39m\"\u001b[39;49m\u001b[39mdepartment_name\u001b[39;49m\u001b[39m\"\u001b[39;49m), col(\u001b[39m\"\u001b[39;49m\u001b[39memployee_name\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m     15\u001b[0m \u001b[39m#showing the result DataFrame\u001b[39;00m\n\u001b[1;32m     16\u001b[0m result_df\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/dataframe.py:3036\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   2991\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mselect\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mcols: \u001b[39m\"\u001b[39m\u001b[39mColumnOrName\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDataFrame\u001b[39m\u001b[39m\"\u001b[39m:  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   2992\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   2993\u001b[0m \n\u001b[1;32m   2994\u001b[0m \u001b[39m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3034\u001b[0m \u001b[39m    +-----+---+\u001b[39;00m\n\u001b[1;32m   3035\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3036\u001b[0m     jdf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mselect(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jcols(\u001b[39m*\u001b[39;49mcols))\n\u001b[1;32m   3037\u001b[0m     \u001b[39mreturn\u001b[39;00m DataFrame(jdf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `employee_name` cannot be resolved. Did you mean one of the following? [`department_name`, `dept_id`].;\n'Project [department_name#39, 'employee_name]\n+- Join LeftSemi, (dept_id#188 = dept_id#94)\n   :- Project [department_id#38 AS dept_id#188, department_name#39]\n   :  +- LogicalRDD [department_id#38, department_name#39], false\n   +- Project [employee_id#32, employee_name#33, department_id#34 AS dept_id#94]\n      +- LogicalRDD [employee_id#32, employee_name#33, department_id#34], false\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#renaming columns in the DataFrames using alias\n",
    "departments_df = departments_df.withColumnRenamed(\"department_id\", \"dept_id\")\n",
    "employees_df = employees_df.withColumnRenamed(\"department_id\", \"dept_id\")\n",
    "\n",
    "#performing a left semi join using the \"dept_id\" column from both DataFrames\n",
    "departments_with_employees_df = departments_df.join(\n",
    "    employees_df,\n",
    "    departments_df[\"dept_id\"] == employees_df[\"dept_id\"],\n",
    "    \"left_semi\"\n",
    ")\n",
    "\n",
    "#selecting department names and employee names\n",
    "result_df = departments_with_employees_df.select(col(\"department_name\"), col(\"employee_name\"))\n",
    "\n",
    "#showing the result DataFrame\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left Anti Joins\n",
    "\n",
    "Question: Find the employees who don't belong to any department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|employee_name|\n",
      "+-------------+\n",
      "|        Alice|\n",
      "|          Eva|\n",
      "|        Grace|\n",
      "|        Henry|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#performing a left anti join to find employees who don't belong to any department\n",
    "employees_without_departments_df = employees_df.join(\n",
    "    departments_df,\n",
    "    employees_df[\"dept_id\"] == departments_df[\"dept_id\"],\n",
    "    \"left_anti\"\n",
    ")\n",
    "\n",
    "#selecting the columns you want to keep\n",
    "result_df = employees_without_departments_df.select(col(\"employee_name\"))\n",
    "\n",
    "#shwoing the employees without departments\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross (Cartesian) Joins\n",
    "\n",
    "Question: Create a DataFrame that contains all possible combinations of employees and departments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `department_id` cannot be resolved. Did you mean one of the following? [`department_name`, `dept_id`, `dept_id`, `employee_id`, `employee_name`].;\n'Project [employee_id#32, 'department_id, employee_name#33, department_name#39]\n+- Join Cross\n   :- Project [employee_id#32, employee_name#33, dept_id#94, 1 AS join_key#210]\n   :  +- Project [employee_id#32, employee_name#33, department_id#34 AS dept_id#94]\n   :     +- LogicalRDD [employee_id#32, employee_name#33, department_id#34], false\n   +- Project [dept_id#188, department_name#39, 1 AS join_key#215]\n      +- Project [department_id#38 AS dept_id#188, department_name#39]\n         +- LogicalRDD [department_id#38, department_name#39], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m cross_joined_df \u001b[39m=\u001b[39m employees_df\u001b[39m.\u001b[39mcrossJoin(departments_df)\n\u001b[1;32m      8\u001b[0m \u001b[39m#selecting the columns you want to keep\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m result_df \u001b[39m=\u001b[39m cross_joined_df\u001b[39m.\u001b[39;49mselect(\u001b[39m\"\u001b[39;49m\u001b[39memployee_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mdepartment_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39memployee_name\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mdepartment_name\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     11\u001b[0m \u001b[39m#shwoing the result DataFrame\u001b[39;00m\n\u001b[1;32m     12\u001b[0m result_df\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/dataframe.py:3036\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   2991\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mselect\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mcols: \u001b[39m\"\u001b[39m\u001b[39mColumnOrName\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDataFrame\u001b[39m\u001b[39m\"\u001b[39m:  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   2992\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   2993\u001b[0m \n\u001b[1;32m   2994\u001b[0m \u001b[39m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3034\u001b[0m \u001b[39m    +-----+---+\u001b[39;00m\n\u001b[1;32m   3035\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3036\u001b[0m     jdf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mselect(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jcols(\u001b[39m*\u001b[39;49mcols))\n\u001b[1;32m   3037\u001b[0m     \u001b[39mreturn\u001b[39;00m DataFrame(jdf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `department_id` cannot be resolved. Did you mean one of the following? [`department_name`, `dept_id`, `dept_id`, `employee_id`, `employee_name`].;\n'Project [employee_id#32, 'department_id, employee_name#33, department_name#39]\n+- Join Cross\n   :- Project [employee_id#32, employee_name#33, dept_id#94, 1 AS join_key#210]\n   :  +- Project [employee_id#32, employee_name#33, department_id#34 AS dept_id#94]\n   :     +- LogicalRDD [employee_id#32, employee_name#33, department_id#34], false\n   +- Project [dept_id#188, department_name#39, 1 AS join_key#215]\n      +- Project [department_id#38 AS dept_id#188, department_name#39]\n         +- LogicalRDD [department_id#38, department_name#39], false\n"
     ]
    }
   ],
   "source": [
    "#creating a new column with a constant value of 1 in both DataFrames\n",
    "employees_df = employees_df.withColumn(\"join_key\", lit(1))\n",
    "departments_df = departments_df.withColumn(\"join_key\", lit(1))\n",
    "\n",
    "#performing a cross join to create all possible combinations\n",
    "cross_joined_df = employees_df.crossJoin(departments_df)\n",
    "\n",
    "#selecting the columns you want to keep\n",
    "result_df = cross_joined_df.select(\"employee_id\", \"department_id\", \"employee_name\", \"department_name\")\n",
    "\n",
    "#shwoing the result DataFrame\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
