{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, when, lit , avg, coalesce , struct,array , explode, create_map,approx_count_distinct,sumDistinct, sum, mean\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"day3\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee Dataframe\n",
      "root\n",
      " |-- Employee_Id: integer (nullable = true)\n",
      " |-- Employee_name: string (nullable = true)\n",
      " |-- department_id: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+\n",
      "|Employee_Id|Employee_name|department_id|\n",
      "+-----------+-------------+-------------+\n",
      "|          1|  Pallavi mam|          101|\n",
      "|          2|          Bob|          102|\n",
      "|          3|        Cathy|          101|\n",
      "|          4|        David|          103|\n",
      "|          5|    Amrit Sir|          104|\n",
      "|          6|        Alice|         null|\n",
      "|          7|          Eva|         null|\n",
      "|          8|        Frank|          110|\n",
      "|          9|        Grace|          109|\n",
      "|         10|        Henry|         null|\n",
      "+-----------+-------------+-------------+\n",
      "\n",
      "Department Dataframe\n",
      "root\n",
      " |-- department_id: integer (nullable = true)\n",
      " |-- department_name: string (nullable = true)\n",
      "\n",
      "+-------------+------------------------+\n",
      "|department_id|department_name         |\n",
      "+-------------+------------------------+\n",
      "|101          |Hr                      |\n",
      "|102          |Engineering             |\n",
      "|103          |Finance                 |\n",
      "|104          |Marketing               |\n",
      "|105          |Operation               |\n",
      "|106          |null                    |\n",
      "|107          |Operations              |\n",
      "|108          |Production              |\n",
      "|null         |Finance                 |\n",
      "|110          |Research and Development|\n",
      "+-------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "employee_data = [(1,'Pallavi mam',101),\n",
    "                 (2,'Bob',102),\n",
    "                 (3,'Cathy',101),\n",
    "                 (4,'David',103),\n",
    "                 (5,'Amrit Sir',104),\n",
    "                 (6,'Alice',None),\n",
    "                 (7,'Eva',None),\n",
    "                 (8,'Frank',110),\n",
    "                 (9,'Grace',109),\n",
    "                 (10,'Henry',None)]\n",
    "\n",
    "Department_Data = [(101,'Hr'),\n",
    "                   (102,'Engineering'),\n",
    "                   (103,'Finance'),\n",
    "                   (104,'Marketing'),\n",
    "                   (105,'Operation'),\n",
    "                   (106,None),\n",
    "                   (107,'Operations'),\n",
    "                   (108,'Production'),\n",
    "                   (None,'Finance'),\n",
    "                   (110,'Research and Development')]\n",
    "\n",
    "employee_schema = StructType([\n",
    "    StructField(\"Employee_Id\",IntegerType(),True),\n",
    "    StructField(\"Employee_name\",StringType(),True),\n",
    "    StructField(\"department_id\",IntegerType(),True)\n",
    "])\n",
    "\n",
    "department_schema = StructType([\n",
    "    StructField(\"department_id\",IntegerType(),True),\n",
    "    StructField(\"department_name\",StringType(),True)\n",
    "])\n",
    "\n",
    "employee_df  = spark.createDataFrame(data=employee_data,schema=employee_schema)\n",
    "department_df = spark.createDataFrame(data=Department_Data, schema=department_schema)\n",
    "\n",
    "print(\"Employee Dataframe\")\n",
    "employee_df.printSchema()\n",
    "employee_df.show()\n",
    "\n",
    "print(\"Department Dataframe\")\n",
    "department_df.printSchema()\n",
    "department_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#registering the DataFrames as temporary SQL tables\n",
    "employee_df.createOrReplaceTempView(\"employees\")\n",
    "department_df.createOrReplaceTempView(\"departments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Expressions\n",
    "\n",
    "Question: How can you combine the employees_df and departments_df DataFrames based on the common \"department_id\" column to get a combined DataFrame with employee names and their respective department names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+------------------------+\n",
      "|employee_id|department_id|Employee_name|department_name         |\n",
      "+-----------+-------------+-------------+------------------------+\n",
      "|1          |101          |Pallavi mam  |Hr                      |\n",
      "|3          |101          |Cathy        |Hr                      |\n",
      "|2          |102          |Bob          |Engineering             |\n",
      "|4          |103          |David        |Finance                 |\n",
      "|5          |104          |Amrit Sir    |Marketing               |\n",
      "|8          |110          |Frank        |Research and Development|\n",
      "+-----------+-------------+-------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#using spark-sql to perform the join\n",
    "combined_df = spark.sql(\"\"\"\n",
    "    SELECT e.employee_id , d.department_id ,e.Employee_name, d.department_name\n",
    "    FROM employees e\n",
    "    JOIN departments d\n",
    "    ON e.department_id = d.department_id\n",
    "\"\"\")\n",
    "\n",
    "# Show the resulting combined DataFrame\n",
    "combined_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inner Joins\n",
    "\n",
    "Question: How can you retrieve employee names and their respective department names for employees belonging to the \"Engineering\" department?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+\n",
      "|Employee_name|department_name|\n",
      "+-------------+---------------+\n",
      "|Bob          |Engineering    |\n",
      "+-------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#using spark-sql to perform the inner join\n",
    "result_df = spark.sql(\"\"\"\n",
    "    SELECT e.Employee_name, d.department_name\n",
    "    FROM employees e\n",
    "    JOIN departments d\n",
    "    ON e.department_id = d.department_id\n",
    "    WHERE d.department_name = 'Engineering'\n",
    "\"\"\")\n",
    "\n",
    "#showing the resulting dataframe\n",
    "result_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outer Joins\n",
    "\n",
    "Question: Retrieve a DataFrame that contains all employees along with their department names. If an employee doesn't have a department assigned, display \"No Department\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------------+\n",
      "|employee_name|department_name         |\n",
      "+-------------+------------------------+\n",
      "|Alice        |No Department           |\n",
      "|Eva          |No Department           |\n",
      "|Henry        |No Department           |\n",
      "|No Employee  |Finance                 |\n",
      "|Pallavi mam  |Hr                      |\n",
      "|Cathy        |Hr                      |\n",
      "|Bob          |Engineering             |\n",
      "|David        |Finance                 |\n",
      "|Amrit Sir    |Marketing               |\n",
      "|No Employee  |Operation               |\n",
      "|No Employee  |No Department           |\n",
      "|No Employee  |Operations              |\n",
      "|No Employee  |Production              |\n",
      "|Grace        |No Department           |\n",
      "|Frank        |Research and Development|\n",
      "+-------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#using spark-sql to perform a left outer join\n",
    "outer_join_sql = spark.sql(\"\"\"\n",
    "    SELECT COALESCE(e.Employee_name, 'No Employee') AS employee_name, \n",
    "           COALESCE(d.department_name, 'No Department') AS department_name\n",
    "    FROM employees e\n",
    "    FULL OUTER JOIN departments d\n",
    "    ON d.department_id = e.department_id\n",
    "\"\"\")\n",
    "\n",
    "#showing the resulting dataframe\n",
    "outer_join_sql.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left Outer Joins\n",
    "\n",
    "Question: List all employees along with their department names. If an employee doesn't have a department assigned, display \"No Department\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+\n",
      "|Employee_name|     department_name|\n",
      "+-------------+--------------------+\n",
      "|  Pallavi mam|                  Hr|\n",
      "|          Bob|         Engineering|\n",
      "|        Cathy|                  Hr|\n",
      "|        David|             Finance|\n",
      "|    Amrit Sir|           Marketing|\n",
      "|        Alice|       No Department|\n",
      "|          Eva|       No Department|\n",
      "|        Frank|Research and Deve...|\n",
      "|        Grace|       No Department|\n",
      "|        Henry|       No Department|\n",
      "+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#using spark-sql to perform a left outer join\n",
    "left_outer_join_sql = spark.sql(\"\"\"\n",
    "    SELECT e.Employee_name, COALESCE(d.department_name, 'No Department') AS department_name\n",
    "    FROM employees e\n",
    "    LEFT JOIN departments d\n",
    "    ON e.department_id = d.department_id\n",
    "\"\"\")\n",
    "#showing the resulting dataframe\n",
    "left_outer_join_sql.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right Outer Joins\n",
    "\n",
    "Question: Display a list of departments along with employee names. If a department has no employees, display \"No Employees\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+\n",
      "|employee_name|     department_name|\n",
      "+-------------+--------------------+\n",
      "|        Cathy|                  Hr|\n",
      "|  Pallavi mam|                  Hr|\n",
      "|          Bob|         Engineering|\n",
      "|        David|             Finance|\n",
      "|    Amrit Sir|           Marketing|\n",
      "| No Employees|           Operation|\n",
      "| No Employees|                null|\n",
      "| No Employees|          Operations|\n",
      "| No Employees|          Production|\n",
      "| No Employees|             Finance|\n",
      "|        Frank|Research and Deve...|\n",
      "+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#using sqark-sql to perform a right outer join\n",
    "right_outer_join_sql = spark.sql(\"\"\"\n",
    "    SELECT COALESCE(e.Employee_name, 'No Employees') AS employee_name, d.department_name\n",
    "    FROM employees e\n",
    "    RIGHT JOIN departments d\n",
    "    ON e.department_id = d.department_id\n",
    "\"\"\")\n",
    "#showing the resulting dataframe\n",
    "right_outer_join_sql.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left Semi Joins\n",
    "\n",
    "Question: Retrieve a DataFrame that includes employee names for departments that have employees.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|Employee_name|\n",
      "+-------------+\n",
      "|  Pallavi mam|\n",
      "|        Cathy|\n",
      "|          Bob|\n",
      "|        David|\n",
      "|    Amrit Sir|\n",
      "|        Frank|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#using spark-sql to perform a left semi join\n",
    "left_semi_join_sql = spark.sql(\"\"\"\n",
    "    SELECT e.Employee_name\n",
    "    FROM employees e\n",
    "    LEFT SEMI JOIN departments d\n",
    "    ON e.department_id = d.department_id\n",
    "\"\"\")\n",
    "\n",
    "#showing the resulting DataFrame\n",
    "left_semi_join_sql.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left Anti Joins\n",
    "\n",
    "Question: Find the employees who don't belong to any department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|Employee_name|\n",
      "+-------------+\n",
      "|        Alice|\n",
      "|          Eva|\n",
      "|        Grace|\n",
      "|        Henry|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#using spark-sql to perform a left anti join\n",
    "left_anti_join_sql = spark.sql(\"\"\"\n",
    "    SELECT e.Employee_name\n",
    "    FROM employees e\n",
    "    LEFT ANTI JOIN departments d\n",
    "    ON e.department_id = d.department_id\n",
    "\"\"\")\n",
    "\n",
    "#showing the resulting dataframe\n",
    "left_anti_join_sql.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross (Cartesian) Joins\n",
    "\n",
    "Question: Create a DataFrame that contains all possible combinations of employees and departments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 117:===============================>                     (60 + 20) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+-------------+--------------------+\n",
      "|Employee_Id|Employee_name|department_id|department_id|     department_name|\n",
      "+-----------+-------------+-------------+-------------+--------------------+\n",
      "|          1|  Pallavi mam|          101|          101|                  Hr|\n",
      "|          1|  Pallavi mam|          101|          102|         Engineering|\n",
      "|          1|  Pallavi mam|          101|          103|             Finance|\n",
      "|          1|  Pallavi mam|          101|          104|           Marketing|\n",
      "|          1|  Pallavi mam|          101|          105|           Operation|\n",
      "|          1|  Pallavi mam|          101|          106|                null|\n",
      "|          1|  Pallavi mam|          101|          107|          Operations|\n",
      "|          1|  Pallavi mam|          101|          108|          Production|\n",
      "|          1|  Pallavi mam|          101|         null|             Finance|\n",
      "|          1|  Pallavi mam|          101|          110|Research and Deve...|\n",
      "|          2|          Bob|          102|          101|                  Hr|\n",
      "|          2|          Bob|          102|          102|         Engineering|\n",
      "|          2|          Bob|          102|          103|             Finance|\n",
      "|          2|          Bob|          102|          104|           Marketing|\n",
      "|          2|          Bob|          102|          105|           Operation|\n",
      "|          2|          Bob|          102|          106|                null|\n",
      "|          2|          Bob|          102|          107|          Operations|\n",
      "|          2|          Bob|          102|          108|          Production|\n",
      "|          2|          Bob|          102|         null|             Finance|\n",
      "|          2|          Bob|          102|          110|Research and Deve...|\n",
      "+-----------+-------------+-------------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#using spark-sql to perform a cross join (Cartesian join)\n",
    "cross_join_sql = spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM employees e\n",
    "    CROSS JOIN departments d\n",
    "\"\"\")\n",
    "\n",
    "#showing the resulting dataframe\n",
    "cross_join_sql.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
